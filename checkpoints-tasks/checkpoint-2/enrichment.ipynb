{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "118cf3b9-ec3d-43bd-a826-dd14563daeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "from custom_functions import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1a7283-437e-4d45-a2c4-9542b0d65c98",
   "metadata": {},
   "source": [
    "#### 1. Загружаем все файлы\n",
    "Так же добавим к ним технические колонки связанные с проекцией и будущим расчетом новых признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5289b3da-4933-4926-a87a-f81ed6fe115d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test\n",
    "train = pd.read_csv('train_test/train.csv', index_col=0)\n",
    "test = pd.read_csv('train_test/test.csv', index_col=0)\n",
    "concat = pd.concat([train, test]).rename(columns={'long': 'lon'}).reset_index(drop=True)\n",
    "geometry = gpd.points_from_xy(concat['lon'], concat['lat'])\n",
    "\n",
    "# Tuning Geoframe\n",
    "data = gpd.GeoDataFrame(concat, geometry=geometry, crs='EPSG:4326')\n",
    "# пока дропнем строки с пропусками координат\n",
    "data.dropna(subset=['lon', 'lat'], inplace=True)\n",
    "\n",
    "data['utm'] = data.apply(lambda x: find_epsg(x.lon, x.lat), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "091ded3a-adf8-4431-b067-2cdb1b9c9908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infrastructure files\n",
    "files_path = glob.glob('fed_districts/*.csv')\n",
    "files = [pd.read_csv(f, index_col=0) for f in files_path]\n",
    "concat_files = pd.concat(files).reset_index(drop=True)\n",
    "geometry_files = gpd.points_from_xy(concat_files['lon'], concat_files['lat'])\n",
    "\n",
    "# Tuning Geoframe\n",
    "infrastructure = gpd.GeoDataFrame(\n",
    "    concat_files, geometry=geometry_files, crs='EPSG:4326'\n",
    ")\n",
    "\n",
    "infrastructure['utm'] = infrastructure.apply(lambda x: find_epsg(x.lon, x.lat), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2717c1-e42e-4503-bfaa-049e91ab9ad3",
   "metadata": {},
   "source": [
    "#### 2. Обогащаем данные \n",
    "Итак, у нас 2 основных задачи: поиск ближайшего к банкомату объекта инфрастуркутры и поиск количества точек инфраструктуры в радиусе 250м. Для корректности вычисляемых величин, нам нужно учесть географическое расположение объектов. Для решения данной задачи воспользуемся разделением объектов (как банкоматов, так и точек инфраструктуры) на UTM зоны."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cc1d1bf-1791-48d7-9530-bed520989d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вытаскиваем массив UTM зон встречающихся в наших данных\n",
    "utm_zones = data['utm'].unique()\n",
    "# Вытаскиваем массив типов инфраструктуры\n",
    "infr_obj = infrastructure['type'].unique()\n",
    "# Пары зона - объект\n",
    "utm_obj = list(product(utm_zones, infr_obj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9e03845-5466-4ff3-a411-b9ab558465f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделяем датафреймы по UTM зоне и записываем в словарь с соответсвующем ключем\n",
    "utm_data = {}\n",
    "for utm in utm_zones:\n",
    "    utm_data[utm] = data[data['utm'] == utm]\n",
    "\n",
    "utm_infrastructure = {}\n",
    "for utm, obj in utm_obj:\n",
    "    mask = (infrastructure['utm'] == utm) & (infrastructure['type'] == obj)\n",
    "    utm_infrastructure[(utm, obj)] = infrastructure[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70745558-a96f-4e8c-b675-623e965bfe57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 325/325 [00:10<00:00, 30.07it/s]\n"
     ]
    }
   ],
   "source": [
    "# Считаем расстояния до ближайшего объекта инфраструктуры\n",
    "for utm, obj in tqdm(utm_obj):\n",
    "    # Имя будущей колонки с дистанцией\n",
    "    dist_col_name = f'nearest_{obj}'\n",
    "    # Корректируем проекцию для текущей итерации\n",
    "    cur_data = utm_data[utm].to_crs(f'EPSG:{utm}')\n",
    "    cur_obj = utm_infrastructure[(utm, obj)].to_crs(f'EPSG:{utm}')\n",
    "    # Добавляем колонку с дистанцией до ближайшего объекта инфраструктуры\n",
    "    dist_to_nearest = (\n",
    "        cur_data.sjoin_nearest(cur_obj, how='left', distance_col='dist')[['id', 'dist']]\n",
    "        .rename(columns={'dist': dist_col_name})\n",
    "        .drop_duplicates(subset='id')\n",
    "    )\n",
    "    utm_data[utm] = pd.merge(utm_data[utm], dist_to_nearest, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "445fe6e9-fefb-431b-af86-bc7a83722600",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:22<00:00,  1.10it/s]\n"
     ]
    }
   ],
   "source": [
    "# Считаем расстояние до ближайшего соседнего банкомата из первичного датасета\n",
    "for utm in tqdm(utm_zones):\n",
    "    try:\n",
    "        utm_data[utm] = dist_to_nearest_neighbour(\n",
    "            utm_data[utm], epsg=f'EPSG:{utm}'\n",
    "        ).to_crs('EPSG:4326')\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fe2e284-58d8-4cb3-b15e-e41e783bc53c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 325/325 [00:10<00:00, 29.76it/s]\n"
     ]
    }
   ],
   "source": [
    "# Считаем количество объектов в радиусе 500м\n",
    "for utm, obj in tqdm(utm_obj):\n",
    "    # Корректируем проекцию для текущей итерации\n",
    "    cur_data = utm_data[utm].to_crs(f'EPSG:{utm}')\n",
    "    cur_obj = utm_infrastructure[(utm, obj)].to_crs(f'EPSG:{utm}')\n",
    "    utm_data[utm] = utm_data[utm].join(points_in_buffer(cur_obj, cur_data, obj, 500))\n",
    "    utm_data[utm].columns.str.contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cb9379a-4c54-46ea-ab37-fb136c0768a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "enriched_data = pd.concat(utm_data.values())\n",
    "# Заполняем пропуски в колонках \"объекты в радиусе\" на ноль\n",
    "enriched_data.loc[:, enriched_data.columns.str.contains(\"_in_\")] = \\\n",
    "    enriched_data.loc[:, enriched_data.columns.str.contains(\"_in_\")\n",
    "].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "050d67e8-a461-46a3-ae45-06c46fed3753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enriched_data.to_csv('train_test/enriched_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
